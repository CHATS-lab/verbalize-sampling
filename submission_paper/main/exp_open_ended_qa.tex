\section{Open-Ended Question Answering}\label{sec:open-ended_qa}
% Building on our findings that \ourslower improves the diversity of LLM outputs, we hypothesize that it can also mitigate stereotypical outputs and encourage a more broad and balanced response distribution. 
Building on the finding that VS improves diversity, this section evaluates whether it can also mitigate stereotypical outputs and generate more balanced answer distributions in open-ended QA tasks.


\begin{wrapfigure}{r}{0.5\textwidth}
    \captionsetup{skip=2pt}
    \centering
    % Figure with its own caption and label
    \begin{minipage}{\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/bias/coverage_n.pdf}
        \captionof{figure}{\textbf{Average Coverage-N} across models on different methods. 
        }
        \label{fig:bias_coverage_n}
    \end{minipage}

    \vspace{4pt}

    \captionof{table}{Coverage test across models: percent of times (\%) VS-Standard fully covers Sequence or Sequence fully covers VS-Standard.}
    \label{tab:bias_coverage_test}
    \resizebox{0.5\textwidth}{!}{
        \centering
        \begin{tabular}{lcc}
        \toprule
        \textbf{Model} & \textbf{VS-Standard(\%)} & \textbf{Sequence(\%)} \\
        \midrule
        GPT-4.1-mini      & 47.5  & 15.0  \\
        GPT-4.1           & 57.5  & 20.0  \\
        Gemini-2.5-Flash  & 45.0  & 15.0  \\
        Gemini-2.5-Pro    & 15.0  & 12.5  \\
        Claude-4-Sonnet   & 40.0  & 30.0  \\
        Deepseek-r1       & 25.0  & 17.5  \\
        o3                & 20.0  & 20.0  \\
        Qwen3-235b        & 37.5  & 22.5  \\
        \bottomrule
        \end{tabular}
    }
    \vspace{-2em}
\end{wrapfigure}

\paragraph{Benchmarks} We use the \textit{CoverageQA}~\citep{wong2024simplestratdiversifyinglanguagemodel} dataset designed to elicit a broad range of valid answers and expose potential bias (e.g., ``Name a US state''   expects all 50 states, revealing whether models overproduce frequent ones like ``California'' while neglecting rare ones like ``Wyoming''). 
Each question has at least 20 ground-truth answers requiring no further reasoning or external knowledge, so that the evaluation strictly focuses on the response coverage. 
To reduce cost, we evaluate VS on 40 questions, combining originals from the \textbf{CoverageQA} dataset~\citep{wong2024simplestratdiversifyinglanguagemodel} with additional ones we created in the same style.  
For each question, we sample $N=100$ responses per method, with each LLM call generating $k=20$ candidates, capturing both within-call (across the $k$ candidates) and across-calls (over the total $N$ responses) diversity.
Full prompts and questions are in \Cref{appendix:prompt}.
% \jiayicomment{50 general + 50 questions from the dataset, how to determine if general use small model and with at least 98\% accuracy}

\paragraph{Evaluation.}
We evaluate bias and coverage using three metrics: (1) \textbf{Coverage-N}, the fraction of unique ground-truth answers generated in $N$ samples; higher values indicate broader coverage. (2) \textbf{KL divergence}, the deviation of the model's answer distribution from uniform; %over ground-truth answers \wyshi{i thought there is no ground-truth?}\jiayicomment{we have ground truth answer but not ground truth distribution}; 
lower values indicate a more balanced distribution. (3) \textbf{Precision}, the proportion of correct answers among all samples; it measures if the increased diversity comes at the expense of correctness. 

\paragraph{Results.}
Figure~\ref{fig:bias_coverage_n} reports average Coverage-N across methods. VS-Standard significantly outperforms direct, CoT, and multi-turn prompting, though its gains over sequence are not statistically significant (see~\Cref{fig:open_ended_qa_combined_results} for KL divergence). VS-Multi achieves the best overall tradeoff, delivering both the highest Coverage-N and lowest KL divergence. 
To further assess diversity, we introduce a coverage test measuring how often responses from VS-Standard fully subsume those from sequence. As shown in Table~\ref{tab:bias_coverage_test}, VS-Standard consistently covers sequence more often than the reverse across models.
However, because of mode collapse, direct prompting yields highly skewed and narrow outputs. For instance, when prompted with ``Name a US State,'' Claude-4-sonnet outputs ``California'' 95 out of 100 times, covering only 2 states. \ours reduces this bias to 5 occurrences of ``California'' and expands coverage to 20 states.
Importantly, as detailed in Table~\ref{tab:all_results_open_ended_qa_general} (Appendix~\ref{appendix:open_ended_qa}) these gains in diversity are achieved without loss of answer quality: precision for VS is stably close to 1 and comparable across all methods.


\newtakeaway{\ours reduces output bias and increases answer coverage without compromising answer quality.}